# ðŸµ Matcha â€” Multi-Modal Perception for End-to-End Reinforcement Learning in Balancing Robots

> *"Balancing, but make it intelligent (and a little bit cute)."* â˜•ðŸ¤–

---

## ðŸŒ± Overview

**Matcha** is our experimental balancing robot project from **Fulbright University Vietnam**, exploring how *reinforcement learning* and *multi-modal perception* can enable robots to self-balance using vision and inertial sensing.

Our current research direction is:
> **Multi-Modal Perception for End-to-End Reinforcement Learning in Balancing Robots:  
A Comparison of Vision-Only and Vision+IMU Policies**

We aim to study how adding different sensory inputs (camera, IMU) affects policy robustness, stability, and real-world transfer in reinforcement-learning-based balance control.

---

## ðŸ§© Research Phases

| Phase | Focus | Description |
|:--:|:--|:--|
| **v1 â€” PPO Baseline** | State-based RL | Trained on pitch, pitch rate, and velocity â€” stable control achieved. |
| **v2 â€” Reward Tuned PPO** | Improved shaping | Adjusted reward weights to enhance stability and smooth motion. |
| **v3 â€” Vision-Only RL** | End-to-End Vision | Replace explicit states with CNN encoder on simulated camera feed. |
| **v4 â€” Vision + IMU Fusion** | Multi-Modal Learning | Combine visual and inertial features for robustness under uncertainty. |
| **v5 â€” Real-World Transfer** | Hardware Validation | Deploy learned policy on physical Matcha robot. |

Each version is trained, evaluated, and logged independently under the `/logs_ppo` directory for reproducibility.

---

## ðŸ§  Model Architecture (Simplified)

    [Camera RGB] â”€â”€â”
                    â”œâ”€â”€â–¶ [Vision Encoder (CNN)] â”€â”
    [IMU Sensor] â”€â”€â”€â”˜                            â”‚
                                                 â–¼
                                           [Feature Fusion]
                                                 â–¼
                                           [PPO Policy Net]
                                                 â–¼
                                           [Motor Commands]

---

## ðŸ‘©â€ðŸ”¬ Team Matcha

| Member | Role | Focus Area |
|:--|:--|:--|
| **Äinh Há»“ng Ngá»c** | Project Manager & AI / CV Engineer | Leads PPO & End-to-End RL pipelines, reward tuning, perception fusion. Also coordinates research documentation and writing.|
| **PhÆ°Æ¡ng Quá»³nh** | Mechanical & Embedded Systems Engineer | Designs robot hardware, integrates IMU + camera, builds simulation-to-real bridge. |
| **Alex** | Research Assistant & Software Support | Runs experiments, manages logs, visualizes data, and supports evaluation pipeline. |
| **Prof. DÆ°Æ¡ng PhÃ¹ng** | ðŸŽ“ Research Advisor (Fulbright University) | Supervises research direction, provides guidance on RL architecture and methodology. |

---

## ðŸ“Š Current Status

- âœ… **PPO Baseline (v1)** â€” Stable up to *12.4 s* average survival.
- âœ… **Reward Tuned PPO (v2)** â€” Stable up to *14 s*, smooth control, mean reward â‰ˆ 1965.
- ðŸš§ **Vision RL (v3)** â€” Preparing simulation camera feed, CNN encoder setup.
- ðŸ§ª **Fusion RL (v4)** â€” Planned: joint embedding of vision + IMU for robust policy learning.
- ðŸ”§ **Hardware Integration** â€” Physical prototype under assembly; IMU streaming functional.

---

## ðŸ§¾ Reproducibility Notes

All experiments follow consistent setup:
- **URDF**: `hardware/balance_robot.urdf`
- **Simulator**: PyBullet (240 Hz)
- **Algorithm**: PPO (Stable-Baselines3)
- **Reward Function (v2)**:

- **Torque limit**: Â±2 NÂ·m  
- **Pitch limit**: 35Â°  
- **Max episode steps**: 1500  
- **Random seeds**: [42, 77, 99]

---

## ðŸ“š Roadmap

- [x] Implement PPO state-based baseline  
- [x] Tune reward & verify stability  
- [ ] Add simulated RGB camera input  
- [ ] Implement Vision-Only PPO policy  
- [ ] Integrate IMU for multi-modal fusion  
- [ ] Validate real-world transfer  
- [ ] Prepare poster & paper for submission âœ¨  

---

## ðŸ§¡ Acknowledgement

This project is supported by the **Fulbright Robotics Lab** and supervised by **Prof. DÆ°Æ¡ng PhÃ¹ng**.  
Matcha is brewed with care â˜•, code, and a little chaos â€” but mostly learning.

---

> â€œEvery time Matcha falls, it learns a little better how to stand.â€  
> â€” *Team Matcha, 2025*
